{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abe15ca",
   "metadata": {},
   "source": [
    "# Ciência de dados - Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1698a7b6",
   "metadata": {},
   "source": [
    "<img src='crisp-dm-nutshell-v3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a649259",
   "metadata": {},
   "source": [
    "## NLP pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6f4676",
   "metadata": {},
   "source": [
    "**Definição:** Processamento de linguagem natural (PLN) é uma vertente da inteligência artificial que ajuda computadores a entender, interpretar e manipular a linguagem humana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5978ca2",
   "metadata": {},
   "source": [
    "<img src='nlp_ml.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0191929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860dca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\"No meio do caminho tinha uma pedra\n",
    "tinha uma pedra no meio do caminho\n",
    "tinha uma pedra\n",
    "no meio do caminho tinha uma pedra.\n",
    "Nunca me esquecerei desse acontecimento\n",
    "na vida de minhas retinas tão fatigadas.\n",
    "Nunca me esquecerei que no meio do caminho\n",
    "tinha uma pedra\n",
    "tinha uma pedra no meio do caminho\n",
    "no meio do caminho tinha uma pedra.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2efdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "estrofe1= \"\"\"no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho tinha uma pedra no meio do caminho tinha uma pedra\"\"\"\n",
    "\n",
    "estrofe2 = \"\"\"nunca me esquecerei desse acontecimento na vida de minhas retinas tão fatigadas nunca me esquecerei que no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho no meio do caminho tinha uma pedra\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4bf8f",
   "metadata": {},
   "source": [
    "**Stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e89658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', 'tinha', 'uma', 'pedra', 'no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', 'no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', '.', 'Nunca', 'me', 'esquecerei', 'desse', 'acontecimento', 'na', 'vida', 'de', 'minhas', 'retinas', 'tão', 'fatigadas', '.', 'Nunca', 'me', 'esquecerei', 'que', 'no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', 'tinha', 'uma', 'pedra', 'no', 'meio', 'do', 'caminho', 'no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', '.']\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "['No', 'meio', 'caminho', 'pedra', 'pedra', 'meio', 'caminho', 'pedra', 'meio', 'caminho', 'pedra', '.', 'Nunca', 'esquecerei', 'desse', 'acontecimento', 'vida', 'retinas', 'tão', 'fatigadas', '.', 'Nunca', 'esquecerei', 'meio', 'caminho', 'pedra', 'pedra', 'meio', 'caminho', 'meio', 'caminho', 'pedra', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('portuguese'))\n",
    "  \n",
    "# tokenize\n",
    "word_tokens = word_tokenize(texto)\n",
    "  \n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "  \n",
    "filtered_sentence = []\n",
    "\n",
    "# remove stop swords\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "  \n",
    "print(word_tokens)\n",
    "print('--------------------------------------------------------------------------------------------------------------')\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879f4e52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d4733d",
   "metadata": {},
   "source": [
    "**Stemming** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45572f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importa o porter stemmer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f6fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(texto)\n",
    "wordstokenized = nltk.word_tokenize(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192e80c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho tinha uma pedra no meio do caminho tinha uma pedra .', 'nunca me esquecerei dess acontecimento na vida de minha retina tão fatigada .', 'nunca me esquecerei que no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho no meio do caminho tinha uma pedra .']\n"
     ]
    }
   ],
   "source": [
    "# Para reduzirmos um termo para sua raiz realizamos o processo de stemming - Essas palavras podem ou não ter um sentido\n",
    "# por exemplo: intelligently - intelligen\n",
    "\n",
    "# instancia o porter stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# primeira forma => output: uma string contendo tudo junto\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    newwords = [stemmer.stem(word) for word in words]\n",
    "    sentences[i] = ' '.join(newwords)\n",
    "\n",
    "print (sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f10001",
   "metadata": {},
   "source": [
    "**Normalização**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2389dd21",
   "metadata": {},
   "source": [
    "Alguns passos importantes: \n",
    "* Colocar todas as palavras em minusculos\n",
    "* Remover pontuações ou símbolos \n",
    "* Retornar o texto para uma única string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b4365e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho tinha uma pedra no meio do caminho tinha uma pedra nunca me esquecerei desse acontecimento na vida de minhas retinas tão fatigadas nunca me esquecerei que no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho no meio do caminho tinha uma pedra\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# deixa todas as letras minúsculas\n",
    "texto_min = texto.lower()\n",
    "\n",
    "# seleciona apenas letras (lembrando que o texto está em português e as letras possuem acento)\n",
    "apenas_letras = re.findall(r'[a-zéóáêâãõç]+', texto_min)\n",
    "\n",
    "# junta o texto, já que o .findall separa em tokens\n",
    "novo_texto = \" \".join(apenas_letras)\n",
    "\n",
    "print(novo_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91077623",
   "metadata": {},
   "source": [
    "## Bag of Words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c2522f",
   "metadata": {},
   "source": [
    "Agora a outra parte: \n",
    "    \n",
    "* Separar nosso texto em tokens;\n",
    "* Criar uma lista para guardarmos o vocabulário;\n",
    "* Fazer um loop para percorrer o texto inteiro;\n",
    "* Criar uma condicional para verificar se a palavra está na lista —fazemos isso porque nosso vocabulário conta apenas as ocorrências únicas, sem repetições de palavras;\n",
    "Caso não esteja, ela é adicionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21f73707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', 'nunca', 'me', 'esquecerei', 'desse', 'acontecimento', 'na', 'vida', 'de', 'minhas', 'retinas', 'tão', 'fatigadas', 'que'] \n",
      " 20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokens = word_tokenize(novo_texto)\n",
    "\n",
    "\n",
    "Vocab = []\n",
    "for token in tokens:\n",
    "    if token not in Vocab:\n",
    "        Vocab.append(token)\n",
    "\n",
    "print(Vocab,\"\\n\",len(Vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bca25c",
   "metadata": {},
   "source": [
    "O proxímo passo é: \n",
    "\n",
    "* Criar uma lista que representa o vetor;\n",
    "* Fazer um loop para percorrer todas as palavras do vocabulário;\n",
    "* Se a palavra estiver no documento, adicionar 1 à lista; caso contrário, adicionar 0;\n",
    "* Transformar a lista final em um array do numpy e retornar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e89fa468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cria_vetor_documento(documento, vocab):\n",
    "    vetor = []\n",
    "\n",
    "    for palavra in vocab:\n",
    "        if palavra in documento:\n",
    "            vetor.append(1)\n",
    "        else:\n",
    "            vetor.append(0)\n",
    "  \n",
    "    return np.array(vetor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42812654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cria_vetor_documento(novo_texto, Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ed73908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho tinha uma pedra no meio do caminho tinha uma pedra nunca me esquecerei desse acontecimento na vida de minhas retinas tão fatigadas nunca me esquecerei que no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho no meio do caminho tinha uma pedra'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novo_texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2a127",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4cf7dc",
   "metadata": {},
   "source": [
    "* Term Frequency (a frequência do termo), que mede a frequência com que um termo ocorre num documento;\n",
    "* Inverse Document Frequency (inverso da frequência nos documentos), que mede o quão importante um termo é no contexto de todos os documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31664f75",
   "metadata": {},
   "source": [
    "<img src='tfidf.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "214a9ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nunca me esquecerei desse acontecimento na vida de minhas retinas tão fatigadas nunca me esquecerei que no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho no meio do caminho tinha uma pedra'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estrofe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f74ec96b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e1_tokens = estrofe1.split()\n",
    "\n",
    "e2_tokens = estrofe2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa6cfa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicionario_de_contagem(vocabulario, documento):\n",
    "  \n",
    "  '''Recebe uma lista com o vocabulario e uma lista de tokens de um documento.\n",
    "  Retorna um dicionario com o numero de vezes que cada palavra do vocabulario\n",
    "  ocorre no documento.'''\n",
    "  \n",
    "  dic = dict.fromkeys(vocabulario, 0)\n",
    "  for palavra in documento:\n",
    "    dic[palavra] += 1\n",
    "  \n",
    "  return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20da2d25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no': 3, 'meio': 3, 'do': 3, 'caminho': 3, 'tinha': 4, 'uma': 4, 'pedra': 4, 'nunca': 0, 'me': 0, 'esquecerei': 0, 'desse': 0, 'acontecimento': 0, 'na': 0, 'vida': 0, 'de': 0, 'minhas': 0, 'retinas': 0, 'tão': 0, 'fatigadas': 0, 'que': 0} \n",
      "\n",
      "{'no': 3, 'meio': 3, 'do': 3, 'caminho': 3, 'tinha': 3, 'uma': 3, 'pedra': 3, 'nunca': 2, 'me': 2, 'esquecerei': 2, 'desse': 1, 'acontecimento': 1, 'na': 1, 'vida': 1, 'de': 1, 'minhas': 1, 'retinas': 1, 'tão': 1, 'fatigadas': 1, 'que': 1}\n"
     ]
    }
   ],
   "source": [
    "e1_dic_cont = dicionario_de_contagem(Vocab, e1_tokens)\n",
    "e2_dic_cont = dicionario_de_contagem(Vocab, e2_tokens)\n",
    "\n",
    "print(e1_dic_cont,'\\n')\n",
    "print(e2_dic_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de12cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaTF(dic_de_cont, doc):     \n",
    "    \n",
    "    tf_dic = {}\n",
    "    \n",
    "    num_palavras_doc = len(doc)     \n",
    "    for palavra, contagem in dic_de_cont.items():         \n",
    "        tf_dic[palavra] = contagem/float(num_palavras_doc)     \n",
    "    \n",
    "    return(tf_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51847b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_tf_bow = calculaTF(e1_dic_cont, e1_tokens)\n",
    "e2_tf_bow = calculaTF(e2_dic_cont, e2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6aa850",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2_dic_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b6e8890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0.08108108108108109,\n",
       " 'meio': 0.08108108108108109,\n",
       " 'do': 0.08108108108108109,\n",
       " 'caminho': 0.08108108108108109,\n",
       " 'tinha': 0.08108108108108109,\n",
       " 'uma': 0.08108108108108109,\n",
       " 'pedra': 0.08108108108108109,\n",
       " 'nunca': 0.05405405405405406,\n",
       " 'me': 0.05405405405405406,\n",
       " 'esquecerei': 0.05405405405405406,\n",
       " 'desse': 0.02702702702702703,\n",
       " 'acontecimento': 0.02702702702702703,\n",
       " 'na': 0.02702702702702703,\n",
       " 'vida': 0.02702702702702703,\n",
       " 'de': 0.02702702702702703,\n",
       " 'minhas': 0.02702702702702703,\n",
       " 'retinas': 0.02702702702702703,\n",
       " 'tão': 0.02702702702702703,\n",
       " 'fatigadas': 0.02702702702702703,\n",
       " 'que': 0.02702702702702703}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2_tf_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7071b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def computaIDF(lista_de_docs):\n",
    "    idf_dic = {}\n",
    "    N = len(lista_de_docs)\n",
    "\n",
    "    for palavra in lista_de_docs[0]:\n",
    "        num_docs_aparece = 0\n",
    "        for doc in lista_de_docs:\n",
    "            if doc[palavra]>0:\n",
    "                num_docs_aparece += 1\n",
    "        \n",
    "        idf_dic[palavra] = math.log10(N / (num_docs_aparece))\n",
    "\n",
    "    return (idf_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af347ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no': 0.0, 'meio': 0.0, 'do': 0.0, 'caminho': 0.0, 'tinha': 0.0, 'uma': 0.0, 'pedra': 0.0, 'nunca': 0.3010299956639812, 'me': 0.3010299956639812, 'esquecerei': 0.3010299956639812, 'desse': 0.3010299956639812, 'acontecimento': 0.3010299956639812, 'na': 0.3010299956639812, 'vida': 0.3010299956639812, 'de': 0.3010299956639812, 'minhas': 0.3010299956639812, 'retinas': 0.3010299956639812, 'tão': 0.3010299956639812, 'fatigadas': 0.3010299956639812, 'que': 0.3010299956639812}\n"
     ]
    }
   ],
   "source": [
    "estrofes_idf = computaIDF([e1_dic_cont, e2_dic_cont])\n",
    "print(estrofes_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1d56323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computaTFIDF(tf_bow, idfs):\n",
    "    tfidf = {}\n",
    "\n",
    "    for palavra in tf_bow:\n",
    "        tf = tf_bow[palavra]\n",
    "        idf = idfs[palavra]\n",
    "        tfidf[palavra] = tf*idf\n",
    "        \n",
    "    return(tfidf)\n",
    "  \n",
    "e1_tfidf = computaTFIDF(e1_tf_bow, estrofes_idf)\n",
    "e2_tfidf = computaTFIDF(e2_tf_bow, estrofes_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10eb6435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-dc4144928319>:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  tfidf_dataframe.drop('index', 1, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>meio</th>\n",
       "      <th>do</th>\n",
       "      <th>caminho</th>\n",
       "      <th>tinha</th>\n",
       "      <th>uma</th>\n",
       "      <th>pedra</th>\n",
       "      <th>nunca</th>\n",
       "      <th>me</th>\n",
       "      <th>esquecerei</th>\n",
       "      <th>desse</th>\n",
       "      <th>acontecimento</th>\n",
       "      <th>na</th>\n",
       "      <th>vida</th>\n",
       "      <th>de</th>\n",
       "      <th>minhas</th>\n",
       "      <th>retinas</th>\n",
       "      <th>tão</th>\n",
       "      <th>fatigadas</th>\n",
       "      <th>que</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>estrofe 1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estrofe 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            no  meio   do  caminho  tinha  uma  pedra     nunca        me  \\\n",
       "estrofe 1  0.0   0.0  0.0      0.0    0.0  0.0    0.0  0.000000  0.000000   \n",
       "estrofe 2  0.0   0.0  0.0      0.0    0.0  0.0    0.0  0.016272  0.016272   \n",
       "\n",
       "           esquecerei     desse  acontecimento        na      vida        de  \\\n",
       "estrofe 1    0.000000  0.000000       0.000000  0.000000  0.000000  0.000000   \n",
       "estrofe 2    0.016272  0.008136       0.008136  0.008136  0.008136  0.008136   \n",
       "\n",
       "             minhas   retinas       tão  fatigadas       que  \n",
       "estrofe 1  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "estrofe 2  0.008136  0.008136  0.008136   0.008136  0.008136  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dataframe = pd.DataFrame([e1_tfidf, e2_tfidf])\n",
    "tfidf_dataframe[\"Estrofes\"] = ['estrofe 1', 'estrofe 2']\n",
    "tfidf_dataframe.reset_index(inplace=True)\n",
    "tfidf_dataframe.drop('index', 1, inplace = True)\n",
    "tfidf_dataframe.set_index('Estrofes', inplace=True)\n",
    "tfidf_dataframe.index.name = None\n",
    "\n",
    "tfidf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62dee96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3a90b",
   "metadata": {},
   "source": [
    "**tfidf usando nltk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da85f43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho tinha uma pedra no meio do caminho tinha uma pedra',\n",
       " 'nunca me esquecerei desse acontecimento na vida de minhas retinas tão fatigadas nunca me esquecerei que no meio do caminho tinha uma pedra tinha uma pedra no meio do caminho no meio do caminho tinha uma pedra']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estrofes = [estrofe1, estrofe2]\n",
    "estrofes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f3241f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acontecimento',\n",
       " 'caminho',\n",
       " 'de',\n",
       " 'desse',\n",
       " 'do',\n",
       " 'esquecerei',\n",
       " 'fatigadas',\n",
       " 'me',\n",
       " 'meio',\n",
       " 'minhas',\n",
       " 'na',\n",
       " 'no',\n",
       " 'nunca',\n",
       " 'pedra',\n",
       " 'que',\n",
       " 'retinas',\n",
       " 'tinha',\n",
       " 'tão',\n",
       " 'uma',\n",
       " 'vida']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(estrofes)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79f62204",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acontecimento</th>\n",
       "      <th>caminho</th>\n",
       "      <th>de</th>\n",
       "      <th>desse</th>\n",
       "      <th>do</th>\n",
       "      <th>esquecerei</th>\n",
       "      <th>fatigadas</th>\n",
       "      <th>me</th>\n",
       "      <th>meio</th>\n",
       "      <th>minhas</th>\n",
       "      <th>na</th>\n",
       "      <th>no</th>\n",
       "      <th>nunca</th>\n",
       "      <th>pedra</th>\n",
       "      <th>que</th>\n",
       "      <th>retinas</th>\n",
       "      <th>tinha</th>\n",
       "      <th>tão</th>\n",
       "      <th>uma</th>\n",
       "      <th>vida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436436</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>0.272435</td>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.272435</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>0.272435</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>0.136217</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>0.136217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acontecimento   caminho        de     desse        do  esquecerei  \\\n",
       "0       0.000000  0.327327  0.000000  0.000000  0.327327    0.000000   \n",
       "1       0.136217  0.290759  0.136217  0.136217  0.290759    0.272435   \n",
       "\n",
       "   fatigadas        me      meio    minhas        na        no     nunca  \\\n",
       "0   0.000000  0.000000  0.327327  0.000000  0.000000  0.327327  0.000000   \n",
       "1   0.136217  0.272435  0.290759  0.136217  0.136217  0.290759  0.272435   \n",
       "\n",
       "      pedra       que   retinas     tinha       tão       uma      vida  \n",
       "0  0.436436  0.000000  0.000000  0.436436  0.000000  0.436436  0.000000  \n",
       "1  0.290759  0.136217  0.136217  0.290759  0.136217  0.290759  0.136217  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estrofes = pd.DataFrame(X.toarray())\n",
    "df_estrofes.columns = vectorizer.get_feature_names()\n",
    "df_estrofes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08726e62",
   "metadata": {},
   "source": [
    "O calculo no sklearn é um pouco diferente: \n",
    "https://medium.com/analytics-vidhya/demonstrating-calculation-of-tf-idf-from-sklearn-4f9526e7e78b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d0d3c",
   "metadata": {},
   "source": [
    "## Exercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c4b46",
   "metadata": {},
   "source": [
    "* Analise descritiva breve: tamanho da base; distribuição das classes;tamanho dos tweets; \n",
    "* Data Prep: remoção de stop words; remoção de links e hastags e pontuações; criação do tfidf\n",
    "* Modelo: Aplicar a arvore de decisão para classificar em relevante e na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a4ab299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('socialmedia_relevant_cols.csv', encoding='latin-1')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a747016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>choose_one</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text choose_one  class_label\n",
       "0                 Just happened a terrible car crash   Relevant            1\n",
       "1  Our Deeds are the Reason of this #earthquake M...   Relevant            1\n",
       "2  Heard about #earthquake is different cities, s...   Relevant            1\n",
       "3  there is a forest fire at spot pond, geese are...   Relevant            1\n",
       "4             Forest fire near La Ronge Sask. Canada   Relevant            1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0d9d249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(df, text_field):\n",
    "    df['text_field'] = df[text_field].apply(lambda elem: re.sub(r\"http\\S+\", \"\", elem))\n",
    "    df['text_field'] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0–9_]+)|[^\\w\\s]|#|http\\S+\", \"\", elem))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7231f8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>choose_one</th>\n",
       "      <th>class_label</th>\n",
       "      <th>text_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>Heard about earthquake is different cities sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>there is a forest fire at spot pond geese are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10871</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>M194 0104 UTC5km S of Volcano Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10872</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>Police investigating after an ebike collided w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10873</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The Latest More Homes Razed by Northern Califo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10874</th>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook HWO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10875</th>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>CityofCalgary has activated its Municipal Emer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10876 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text choose_one  \\\n",
       "0                     Just happened a terrible car crash   Relevant   \n",
       "1      Our Deeds are the Reason of this #earthquake M...   Relevant   \n",
       "2      Heard about #earthquake is different cities, s...   Relevant   \n",
       "3      there is a forest fire at spot pond, geese are...   Relevant   \n",
       "4                 Forest fire near La Ronge Sask. Canada   Relevant   \n",
       "...                                                  ...        ...   \n",
       "10871  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   Relevant   \n",
       "10872  Police investigating after an e-bike collided ...   Relevant   \n",
       "10873  The Latest: More Homes Razed by Northern Calif...   Relevant   \n",
       "10874  MEG issues Hazardous Weather Outlook (HWO) htt...   Relevant   \n",
       "10875  #CityofCalgary has activated its Municipal Eme...   Relevant   \n",
       "\n",
       "       class_label                                         text_field  \n",
       "0                1                 Just happened a terrible car crash  \n",
       "1                1  Our Deeds are the Reason of this earthquake Ma...  \n",
       "2                1  Heard about earthquake is different cities sta...  \n",
       "3                1  there is a forest fire at spot pond geese are ...  \n",
       "4                1              Forest fire near La Ronge Sask Canada  \n",
       "...            ...                                                ...  \n",
       "10871            1              M194 0104 UTC5km S of Volcano Hawaii   \n",
       "10872            1  Police investigating after an ebike collided w...  \n",
       "10873            1  The Latest More Homes Razed by Northern Califo...  \n",
       "10874            1          MEG issues Hazardous Weather Outlook HWO   \n",
       "10875            1  CityofCalgary has activated its Municipal Emer...  \n",
       "\n",
       "[10876 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize_text(df, 'text')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
